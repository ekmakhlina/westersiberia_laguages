{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from nltk import word_tokenize, wordpunct_tokenize\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load morphed text\n",
    "import pandas as pd\n",
    "import csv\n",
    "a = pd.read_csv('lehtisalo_8_morf.txt', sep='\\t', quoting=csv.QUOTE_NONE,\n",
    "                names=['Cyrillic token', 'Munkácsi token', 'Wichmann token', 'Steinitz token', 'SzOCh token',\n",
    "                       'RME token', 'Hajdú token', 'Mus token', 'IPA token', 'segmented token',\n",
    "                       'lemma', 'Hungarian gloss', 'English gloss', 'POS tag', 'RUS/-'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cyrillic token</th>\n",
       "      <th>Munkácsi token</th>\n",
       "      <th>Wichmann token</th>\n",
       "      <th>Steinitz token</th>\n",
       "      <th>SzOCh token</th>\n",
       "      <th>RME token</th>\n",
       "      <th>Hajdú token</th>\n",
       "      <th>Mus token</th>\n",
       "      <th>IPA token</th>\n",
       "      <th>segmented token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>Hungarian gloss</th>\n",
       "      <th>English gloss</th>\n",
       "      <th>POS tag</th>\n",
       "      <th>RUS/-</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>тадебе</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>tādʼebe</td>\n",
       "      <td>tadʼebe</td>\n",
       "      <td>tadʲebe</td>\n",
       "      <td>-</td>\n",
       "      <td>тадебя</td>\n",
       "      <td>-</td>\n",
       "      <td>shaman</td>\n",
       "      <td>N</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>выʼ</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>wīʔ</td>\n",
       "      <td>wiʔ</td>\n",
       "      <td>wiːʔ</td>\n",
       "      <td>-</td>\n",
       "      <td>выʼ</td>\n",
       "      <td>-</td>\n",
       "      <td>tundra</td>\n",
       "      <td>N</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ңавнанта</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>ŋāwnanta</td>\n",
       "      <td>ŋawnanta</td>\n",
       "      <td>ŋawnăntă</td>\n",
       "      <td>-</td>\n",
       "      <td>ңавна</td>\n",
       "      <td>-</td>\n",
       "      <td>previously:Gen.PxSg3</td>\n",
       "      <td>Adv.Temp</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Cyrillic token Munkácsi token Wichmann token Steinitz token SzOCh token  \\\n",
       "0         тадебе              -              -              -           -   \n",
       "1            выʼ              -              -              -           -   \n",
       "2              .              -              -              -           -   \n",
       "3            NaN            NaN            NaN            NaN         NaN   \n",
       "4       ңавнанта              -              -              -           -   \n",
       "\n",
       "  RME token Hajdú token Mus token IPA token segmented token   lemma  \\\n",
       "0         -     tādʼebe   tadʼebe   tadʲebe               -  тадебя   \n",
       "1         -         wīʔ       wiʔ      wiːʔ               -     выʼ   \n",
       "2         -           .         .         .               -       .   \n",
       "3       NaN         NaN       NaN       NaN             NaN     NaN   \n",
       "4         -    ŋāwnanta  ŋawnanta  ŋawnăntă               -   ңавна   \n",
       "\n",
       "  Hungarian gloss         English gloss   POS tag RUS/-  \n",
       "0               -                shaman         N     -  \n",
       "1               -                tundra         N     -  \n",
       "2               -                     .         .     -  \n",
       "3             NaN                   NaN       NaN   NaN  \n",
       "4               -  previously:Gen.PxSg3  Adv.Temp     -  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Cyrillic token</th>\n",
       "      <th>Munkácsi token</th>\n",
       "      <th>Wichmann token</th>\n",
       "      <th>Steinitz token</th>\n",
       "      <th>SzOCh token</th>\n",
       "      <th>RME token</th>\n",
       "      <th>Hajdú token</th>\n",
       "      <th>Mus token</th>\n",
       "      <th>IPA token</th>\n",
       "      <th>segmented token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>Hungarian gloss</th>\n",
       "      <th>English gloss</th>\n",
       "      <th>POS tag</th>\n",
       "      <th>RUS/-</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>тадебе</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>tādʼebe</td>\n",
       "      <td>tadʼebe</td>\n",
       "      <td>tadʲebe</td>\n",
       "      <td>-</td>\n",
       "      <td>тадебя</td>\n",
       "      <td>-</td>\n",
       "      <td>shaman</td>\n",
       "      <td>N</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>выʼ</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>wīʔ</td>\n",
       "      <td>wiʔ</td>\n",
       "      <td>wiːʔ</td>\n",
       "      <td>-</td>\n",
       "      <td>выʼ</td>\n",
       "      <td>-</td>\n",
       "      <td>tundra</td>\n",
       "      <td>N</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ңавнанта</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>ŋāwnanta</td>\n",
       "      <td>ŋawnanta</td>\n",
       "      <td>ŋawnăntă</td>\n",
       "      <td>-</td>\n",
       "      <td>ңавна</td>\n",
       "      <td>-</td>\n",
       "      <td>previously:Gen.PxSg3</td>\n",
       "      <td>Adv.Temp</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>хунананта</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>xunanānta</td>\n",
       "      <td>xunananta</td>\n",
       "      <td>xunănantă</td>\n",
       "      <td>-</td>\n",
       "      <td>хуна</td>\n",
       "      <td>-</td>\n",
       "      <td>where:Indet.Loc.PxSg3</td>\n",
       "      <td>Pron</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index Cyrillic token Munkácsi token Wichmann token Steinitz token  \\\n",
       "0      0         тадебе              -              -              -   \n",
       "1      1            выʼ              -              -              -   \n",
       "2      2              .              -              -              -   \n",
       "3      4       ңавнанта              -              -              -   \n",
       "4      5      хунананта              -              -              -   \n",
       "\n",
       "  SzOCh token RME token Hajdú token  Mus token  IPA token segmented token  \\\n",
       "0           -         -     tādʼebe    tadʼebe    tadʲebe               -   \n",
       "1           -         -         wīʔ        wiʔ       wiːʔ               -   \n",
       "2           -         -           .          .          .               -   \n",
       "3           -         -    ŋāwnanta   ŋawnanta   ŋawnăntă               -   \n",
       "4           -         -   xunanānta  xunananta  xunănantă               -   \n",
       "\n",
       "    lemma Hungarian gloss          English gloss   POS tag RUS/-  \n",
       "0  тадебя               -                 shaman         N     -  \n",
       "1     выʼ               -                 tundra         N     -  \n",
       "2       .               -                      .         .     -  \n",
       "3   ңавна               -   previously:Gen.PxSg3  Adv.Temp     -  \n",
       "4    хуна               -  where:Indet.Loc.PxSg3      Pron     -  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop all rows with NaN\n",
    "a = a.dropna(how='all').reset_index() \n",
    "a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwith open(\\'lehtisalo3_eng.txt\\') as f2:\\n    lines = f2.readlines()\\nfor i in range(len(lines)):\\n    lines[i] = lines[i][2:].strip()\\n    \\n    \\ndef translation_to_sentences(original_lines=lines):\\n#doing some magic to align our data\\n    new_lines = []\\n    for line in original_lines:\\n        line = line.replace(\\'.\"\\',\\'&1@\\')\\n        line = line.replace(\\'?\"\\',\\'&2@\\')\\n        line = line.replace(\\'!\"\\',\\'&3@\\')\\n        split_line = line.replace(\\'.\\',\\'.@\\').replace(\\'!\\',\\'!@\\').replace(\\'?\\', \\'?@\\').split(\\'@\\')\\n        for j in split_line:\\n            if j != \\'\\':\\n                j = j.replace(\\'&1\\', \\'.\"\\').replace(\\'&2\\', \\'?\"\\').replace(\\'&3\\', \\'!\"\\')\\n                new_lines.append(j)\\n                \\n    return new_lines\\n\\n\\ntranslation_lines = translation_to_sentences()      \\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load translation file\n",
    "'''\n",
    "with open('lehtisalo3_eng.txt') as f2:\n",
    "    lines = f2.readlines()\n",
    "for i in range(len(lines)):\n",
    "    lines[i] = lines[i][2:].strip()\n",
    "    \n",
    "    \n",
    "def translation_to_sentences(original_lines=lines):\n",
    "#doing some magic to align our data\n",
    "    new_lines = []\n",
    "    for line in original_lines:\n",
    "        line = line.replace('.\"','&1@')\n",
    "        line = line.replace('?\"','&2@')\n",
    "        line = line.replace('!\"','&3@')\n",
    "        split_line = line.replace('.','.@').replace('!','!@').replace('?', '?@').split('@')\n",
    "        for j in split_line:\n",
    "            if j != '':\n",
    "                j = j.replace('&1', '.\"').replace('&2', '?\"').replace('&3', '!\"')\n",
    "                new_lines.append(j)\n",
    "                \n",
    "    return new_lines\n",
    "\n",
    "\n",
    "translation_lines = translation_to_sentences()      \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sentences_from_data(data=a):\n",
    "                             #translation=translation_lines):\n",
    "    all_sentences = []\n",
    "    sentence = ''\n",
    "    glosses = ''\n",
    "    morphemes = ''\n",
    "    skip = False\n",
    "    sentence_count = 0\n",
    "\n",
    "    for i in range(len(a)):\n",
    "        if skip:\n",
    "            skip = False\n",
    "            continue\n",
    "        if a['Cyrillic token'][i] != '.' and a['Cyrillic token'][i] != '?' and a['Cyrillic token'][i] != '!':\n",
    "            glosses += a['English gloss'][i] + ' '\n",
    "            morphemes += a['lemma'][i] + ' '\n",
    "            if a['Cyrillic token'][i] not in string.punctuation:\n",
    "                sentence += a['Cyrillic token'][i] + ' '\n",
    "            elif a['Cyrillic token'][i] == '\"':\n",
    "                sentence += a['Cyrillic token'][i]\n",
    "            else:\n",
    "                sentence = sentence.strip() + a['Cyrillic token'][i] + ' '\n",
    "        else:\n",
    "            glosses += a['English gloss'][i] + ' '\n",
    "            morphemes += a['lemma'][i]\n",
    "            sentence = sentence.strip()\n",
    "            sentence += a['Cyrillic token'][i]\n",
    "            skip = False\n",
    "            if i < len(a) - 1:\n",
    "                if a['Cyrillic token'][i+1] =='\"':\n",
    "                    sentence += a['Cyrillic token'][i+1]\n",
    "                    skip = True\n",
    "            all_sentences.append(OrderedDict({\n",
    "                'sentence': sentence,\n",
    "                'morphemes': morphemes,\n",
    "                'glosses': glosses\n",
    "                #'translation': translation[sentence_count]\n",
    "            }))\n",
    "            sentence = ''\n",
    "            glosses = ''\n",
    "            morphemes = ''\n",
    "            sentence_count += 1\n",
    "            \n",
    "\n",
    "    return all_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>morphemes</th>\n",
       "      <th>glosses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>тадебе выʼ.</td>\n",
       "      <td>тадебя выʼ .</td>\n",
       "      <td>shaman tundra .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ңавнанта хунананта я мидахана ңобʼ весоку выри...</td>\n",
       "      <td>ңавна хуна я мись ңобʼ вэсако вырире серодета ...</td>\n",
       "      <td>previously:Gen.PxSg3 where:Indet.Loc.PxSg3 lan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>пада сиде неде ңэвы.</td>\n",
       "      <td>пыда сидя не ңэсь .</td>\n",
       "      <td>he:Sg3 two wife:PxSg3 be:Narr.ScSg3 .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ңобʼ тане хуна вырире ма: \"сидяв пухув, тебтаʼ...</td>\n",
       "      <td>ңобʼ таняʼ хуна вырире манзь : \" сидя пуху , т...</td>\n",
       "      <td>one to there:Spat.Dat where:Indet Virire tell:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>тикы есе инявна манеʼ нумтʼ танаңкунаʼ.\"</td>\n",
       "      <td>тикы еся иня маняʼ нумʼ танась .</td>\n",
       "      <td>this iron rope:Pros we:Pl1 sky:Dat climb up:Fu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0                                        тадебе выʼ.   \n",
       "1  ңавнанта хунананта я мидахана ңобʼ весоку выри...   \n",
       "2                               пада сиде неде ңэвы.   \n",
       "3  ңобʼ тане хуна вырире ма: \"сидяв пухув, тебтаʼ...   \n",
       "4           тикы есе инявна манеʼ нумтʼ танаңкунаʼ.\"   \n",
       "\n",
       "                                           morphemes  \\\n",
       "0                                       тадебя выʼ .   \n",
       "1  ңавна хуна я мись ңобʼ вэсако вырире серодета ...   \n",
       "2                                пыда сидя не ңэсь .   \n",
       "3  ңобʼ таняʼ хуна вырире манзь : \" сидя пуху , т...   \n",
       "4                   тикы еся иня маняʼ нумʼ танась .   \n",
       "\n",
       "                                             glosses  \n",
       "0                                   shaman tundra .   \n",
       "1  previously:Gen.PxSg3 where:Indet.Loc.PxSg3 lan...  \n",
       "2             he:Sg3 two wife:PxSg3 be:Narr.ScSg3 .   \n",
       "3  one to there:Spat.Dat where:Indet Virire tell:...  \n",
       "4  this iron rope:Pros we:Pl1 sky:Dat climb up:Fu...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(make_sentences_from_data())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_into_tokens(s):\n",
    "    ll = [[word_tokenize(w), ' '] for w in s.split()]\n",
    "    s_list = list(itertools.chain(*list(itertools.chain(*ll))))\n",
    "    return s_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sentence_words_arr(all_sentences, i):\n",
    "    wf_arr = []\n",
    "    tokens = string_into_tokens(all_sentences['sentence'][i])\n",
    "    morphemes = all_sentences['morphemes'][i].split()\n",
    "    glosses = all_sentences['glosses'][i].split()\n",
    "    j = 0\n",
    "    off_start = 0\n",
    "    sentence_index = 0\n",
    "    for k in range(len(tokens)):\n",
    "        if tokens[k] == ' ':\n",
    "            off_start += len(tokens[k])\n",
    "            continue\n",
    "        elif tokens[k] in string.punctuation:\n",
    "            wf_arr.append(collections.OrderedDict({\n",
    "                'wf': tokens[k],\n",
    "                'wtype': 'punct',\n",
    "                'off_start': off_start,\n",
    "                'off_end': off_start + len(tokens[k]),\n",
    "                'next_word': sentence_index+1,\n",
    "                'sentence_index': sentence_index\n",
    "                #'ana': False\n",
    "            }))\n",
    "            sentence_index += 1\n",
    "        else:\n",
    "            wf_arr.append(collections.OrderedDict({\n",
    "                'wf': tokens[k],\n",
    "                'wtype': 'word',\n",
    "                'off_start': off_start,\n",
    "                'off_end': off_start + len(tokens[k]),\n",
    "                'next_word': sentence_index+1,\n",
    "                'sentence_index': sentence_index,\n",
    "                'ana': [{'glosses': glosses[j], 'morphemes': morphemes[j]}]\n",
    "                #\"ana\": [{\"lex\": \"ojorsp\", \"gr.pos\": \"V\", \"gr.pers\": \"2\", \"gr.tense\": \"t1\"}]\n",
    "            }))\n",
    "            j += 1\n",
    "            sentence_index += 1\n",
    "        off_start += len(tokens[k])\n",
    "    return wf_arr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wf</th>\n",
       "      <th>wtype</th>\n",
       "      <th>off_start</th>\n",
       "      <th>off_end</th>\n",
       "      <th>next_word</th>\n",
       "      <th>sentence_index</th>\n",
       "      <th>ana</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>пада</td>\n",
       "      <td>word</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'glosses': 'he:Sg3', 'morphemes': 'пыда'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>сиде</td>\n",
       "      <td>word</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[{'glosses': 'two', 'morphemes': 'сидя'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>неде</td>\n",
       "      <td>word</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>[{'glosses': 'wife:PxSg3', 'morphemes': 'не'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ңэвы</td>\n",
       "      <td>word</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>[{'glosses': 'be:Narr.ScSg3', 'morphemes': 'ңэ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.</td>\n",
       "      <td>punct</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     wf  wtype  off_start  off_end  next_word  sentence_index  \\\n",
       "0  пада   word          0        4          1               0   \n",
       "1  сиде   word          5        9          2               1   \n",
       "2  неде   word         10       14          3               2   \n",
       "3  ңэвы   word         15       19          4               3   \n",
       "4     .  punct         19       20          5               4   \n",
       "\n",
       "                                                 ana  \n",
       "0       [{'glosses': 'he:Sg3', 'morphemes': 'пыда'}]  \n",
       "1          [{'glosses': 'two', 'morphemes': 'сидя'}]  \n",
       "2     [{'glosses': 'wife:PxSg3', 'morphemes': 'не'}]  \n",
       "3  [{'glosses': 'be:Narr.ScSg3', 'morphemes': 'ңэ...  \n",
       "4                                                NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(make_sentence_words_arr(df, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    all_sentences.append(collections.OrderedDict({\n",
    "            'text': df['sentence'][i],\n",
    "            'words': make_sentence_words_arr(df, i),\n",
    "            'lang': 0\n",
    "        }))\n",
    "    \n",
    "#print(all_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>тадебе выʼ.</td>\n",
       "      <td>[{'wf': 'тадебе', 'wtype': 'word', 'off_start'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ңавнанта хунананта я мидахана ңобʼ весоку выри...</td>\n",
       "      <td>[{'wf': 'ңавнанта', 'wtype': 'word', 'off_star...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>пада сиде неде ңэвы.</td>\n",
       "      <td>[{'wf': 'пада', 'wtype': 'word', 'off_start': ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ңобʼ тане хуна вырире ма: \"сидяв пухув, тебтаʼ...</td>\n",
       "      <td>[{'wf': 'ңобʼ', 'wtype': 'word', 'off_start': ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>тикы есе инявна манеʼ нумтʼ танаңкунаʼ.\"</td>\n",
       "      <td>[{'wf': 'тикы', 'wtype': 'word', 'off_start': ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                                        тадебе выʼ.   \n",
       "1  ңавнанта хунананта я мидахана ңобʼ весоку выри...   \n",
       "2                               пада сиде неде ңэвы.   \n",
       "3  ңобʼ тане хуна вырире ма: \"сидяв пухув, тебтаʼ...   \n",
       "4           тикы есе инявна манеʼ нумтʼ танаңкунаʼ.\"   \n",
       "\n",
       "                                               words  lang  \n",
       "0  [{'wf': 'тадебе', 'wtype': 'word', 'off_start'...     0  \n",
       "1  [{'wf': 'ңавнанта', 'wtype': 'word', 'off_star...     0  \n",
       "2  [{'wf': 'пада', 'wtype': 'word', 'off_start': ...     0  \n",
       "3  [{'wf': 'ңобʼ', 'wtype': 'word', 'off_start': ...     0  \n",
       "4  [{'wf': 'тикы', 'wtype': 'word', 'off_start': ...     0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_sentences).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_text = {\n",
    "    \"sentences\": all_sentences,\n",
    "    \"meta\": {\"author\": \"Lehtisalo, Toivo\", \"title\": \"Juraksamojedische Volksdichtung. Suomalais-Ugrilainen Seura, Helsinki\", \"year\": 1947, \"id\": 2}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('data_old8.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(one_text, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
